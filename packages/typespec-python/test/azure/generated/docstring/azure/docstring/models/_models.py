# coding=utf-8
# --------------------------------------------------------------------------
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License. See License.txt in the project root for license information.
# Code generated by Microsoft (R) Python Code Generator.
# Changes may cause incorrect behavior and will be lost if the code is regenerated.
# --------------------------------------------------------------------------
# pylint: disable=useless-super-delegation

from typing import Any, Mapping, overload

from .._utils.model_base import Model as _Model, rest_field


class DocModel(_Model):
    """DocModel.

    :ivar doc1: An array of tools the model may call while generating a response.
     You can specify which tool to use by setting the ``tool_choice`` parameter.

     The two categories of tools you can provide the model are:

     * **Built-in tools**: Tools that are provided by OpenAI that extend the model's
       capabilities, like file search.
     * **Function calls (custom tools)**: Functions that are defined by you, enabling the model
       to call your own code. Required.
    :vartype doc1: str
    :ivar doc2: Specifies the processing type used for serving the request.

     * If set to 'auto', then the request will be processed with the service tier configured in
       the Project settings. Unless otherwise configured, the Project will use 'default'.
     * If set to 'default', then the request will be processed with the standard pricing and
       performance for the selected model.
     * If set to '[flex](https://platform.openai.com/docs/guides/flex-processing)' or
       'priority', then the request will be processed with the corresponding service tier. [Contact
       sales](https://openai.com/contact-sales) to learn more about Priority processing.
     * When not set, the default behavior is 'auto'.

     When the ``service_tier`` parameter is set, the response body will include the
     ``service_tier``
     value based on the processing mode actually used to serve the request. This response value
     may be different from the value set in the parameter. Required.
    :vartype doc2: str
    """

    doc1: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """An array of tools the model may call while generating a response.
      You can specify which tool to use by setting the ``tool_choice`` parameter.
 
      The two categories of tools you can provide the model are:
 
      * **Built-in tools**: Tools that are provided by OpenAI that extend the model's
        capabilities, like file search.
      * **Function calls (custom tools)**: Functions that are defined by you, enabling the model
        to call your own code. Required."""
    doc2: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Specifies the processing type used for serving the request.
 
      * If set to 'auto', then the request will be processed with the service tier configured in
        the Project settings. Unless otherwise configured, the Project will use 'default'.
      * If set to 'default', then the request will be processed with the standard pricing and
        performance for the selected model.
      * If set to '[flex](https://platform.openai.com/docs/guides/flex-processing)' or
        'priority', then the request will be processed with the corresponding service tier. [Contact
        sales](https://openai.com/contact-sales) to learn more about Priority processing.
      * When not set, the default behavior is 'auto'.
 
      When the ``service_tier`` parameter is set, the response body will include the
      ``service_tier``
      value based on the processing mode actually used to serve the request. This response value
      may be different from the value set in the parameter. Required."""

    @overload
    def __init__(
        self,
        *,
        doc1: str,
        doc2: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
